{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim\n",
    "#!pip install tokenizers\n",
    "from pathlib import Path\n",
    "save_path = 'tokenized_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import GPT2Config\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(save_path)\n",
    "tokenizer.add_special_tokens({\n",
    "  \"eos_token\": \"</s>\",\n",
    "  \"bos_token\": \"<s>\",\n",
    "  \"unk_token\": \"<unk>\",\n",
    "  \"pad_token\": \"<pad>\",\n",
    "  \"mask_token\": \"<mask>\"\n",
    "})# creating the configurations from which the model can be made\n",
    "config = GPT2Config(\n",
    "  vocab_size=tokenizer.vocab_size,\n",
    "  bos_token_id=tokenizer.bos_token_id,\n",
    "  eos_token_id=tokenizer.eos_token_id\n",
    ")# creating the model\n",
    "model = TFGPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('single_string.txt', \"r\", encoding='utf-8') as f:\n",
    "    single_string = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [single_string[i:i + 10000000] for i in range(0, len(single_string), 10000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 10000000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks), len(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk: 0\n",
      "chunk: 1\n",
      "chunk: 2\n",
      "chunk: 3\n",
      "chunk: 4\n",
      "chunk: 5\n",
      "chunk: 6\n",
      "chunk: 7\n",
      "chunk: 8\n",
      "chunk: 9\n",
      "chunk: 10\n",
      "chunk: 11\n",
      "chunk: 12\n",
      "chunk: 13\n",
      "chunk: 14\n",
      "chunk: 15\n",
      "chunk: 16\n",
      "chunk: 17\n",
      "chunk: 18\n",
      "chunk: 19\n",
      "chunk: 20\n",
      "chunk: 21\n",
      "chunk: 22\n",
      "chunk: 23\n",
      "chunk: 24\n",
      "chunk: 25\n",
      "chunk: 26\n",
      "chunk: 27\n",
      "chunk: 28\n",
      "chunk: 29\n",
      "chunk: 30\n",
      "chunk: 31\n",
      "chunk: 32\n",
      "chunk: 33\n",
      "chunk: 34\n",
      "chunk: 35\n",
      "chunk: 36\n",
      "chunk: 37\n",
      "chunk: 38\n",
      "chunk: 39\n",
      "chunk: 40\n",
      "chunk: 41\n",
      "chunk: 42\n",
      "chunk: 43\n",
      "chunk: 44\n",
      "chunk: 45\n",
      "chunk: 46\n",
      "chunk: 47\n",
      "chunk: 48\n",
      "chunk: 49\n",
      "chunk: 50\n",
      "chunk: 51\n",
      "chunk: 52\n",
      "chunk: 53\n",
      "chunk: 54\n",
      "chunk: 55\n",
      "chunk: 56\n",
      "chunk: 57\n",
      "chunk: 58\n",
      "chunk: 59\n",
      "chunk: 60\n",
      "chunk: 61\n",
      "chunk: 62\n",
      "chunk: 63\n",
      "chunk: 64\n",
      "chunk: 65\n",
      "chunk: 66\n",
      "chunk: 67\n",
      "chunk: 68\n",
      "chunk: 69\n",
      "chunk: 70\n",
      "chunk: 71\n",
      "chunk: 72\n",
      "chunk: 73\n",
      "chunk: 74\n",
      "chunk: 75\n",
      "chunk: 76\n",
      "chunk: 77\n",
      "chunk: 78\n",
      "chunk: 79\n",
      "chunk: 80\n",
      "chunk: 81\n",
      "chunk: 82\n",
      "chunk: 83\n",
      "chunk: 84\n",
      "chunk: 85\n",
      "chunk: 86\n",
      "chunk: 87\n",
      "chunk: 88\n",
      "chunk: 89\n",
      "chunk: 90\n",
      "chunk: 91\n",
      "chunk: 92\n",
      "chunk: 93\n",
      "chunk: 94\n",
      "chunk: 95\n",
      "chunk: 96\n",
      "chunk: 97\n",
      "chunk: 98\n",
      "chunk: 99\n",
      "chunk: 100\n",
      "chunk: 101\n",
      "chunk: 102\n",
      "chunk: 103\n",
      "chunk: 104\n",
      "chunk: 105\n",
      "chunk: 106\n",
      "chunk: 107\n",
      "chunk: 108\n",
      "chunk: 109\n",
      "chunk: 110\n",
      "chunk: 111\n",
      "chunk: 112\n",
      "chunk: 113\n",
      "chunk: 114\n",
      "chunk: 115\n",
      "chunk: 116\n",
      "chunk: 117\n",
      "chunk: 118\n",
      "chunk: 119\n",
      "chunk: 120\n",
      "chunk: 121\n",
      "chunk: 122\n",
      "chunk: 123\n",
      "chunk: 124\n",
      "chunk: 125\n",
      "chunk: 126\n",
      "chunk: 127\n",
      "chunk: 128\n",
      "chunk: 129\n",
      "chunk: 130\n",
      "chunk: 131\n",
      "chunk: 137\n",
      "chunk: 138\n",
      "chunk: 139\n",
      "chunk: 140\n",
      "chunk: 141\n",
      "chunk: 142\n",
      "chunk: 143\n",
      "chunk: 144\n",
      "chunk: 145\n",
      "chunk: 146\n",
      "chunk: 147\n",
      "chunk: 148\n",
      "chunk: 149\n",
      "chunk: 150\n",
      "chunk: 151\n",
      "chunk: 152\n",
      "chunk: 153\n",
      "chunk: 154\n",
      "chunk: 155\n",
      "chunk: 156\n",
      "chunk: 157\n",
      "chunk: 158\n",
      "chunk: 159\n",
      "chunk: 160\n",
      "chunk: 161\n",
      "chunk: 162\n",
      "chunk: 163\n",
      "chunk: 164\n",
      "chunk: 165\n",
      "chunk: 166\n",
      "chunk: 167\n",
      "chunk: 168\n",
      "chunk: 169\n",
      "chunk: 170\n",
      "chunk: 171\n",
      "chunk: 172\n",
      "chunk: 173\n",
      "chunk: 174\n",
      "chunk: 175\n",
      "chunk: 176\n",
      "chunk: 177\n",
      "chunk: 178\n",
      "chunk: 179\n",
      "chunk: 180\n",
      "chunk: 181\n",
      "chunk: 182\n",
      "chunk: 183\n",
      "chunk: 184\n",
      "chunk: 185\n",
      "chunk: 186\n",
      "chunk: 187\n",
      "chunk: 188\n",
      "chunk: 189\n",
      "chunk: 190\n",
      "chunk: 191\n",
      "chunk: 192\n",
      "chunk: 193\n",
      "chunk: 194\n",
      "chunk: 195\n",
      "chunk: 196\n",
      "chunk: 197\n",
      "chunk: 198\n",
      "chunk: 199\n",
      "chunk: 200\n",
      "chunk: 201\n",
      "chunk: 202\n",
      "chunk: 203\n",
      "chunk: 204\n",
      "chunk: 205\n",
      "chunk: 206\n",
      "chunk: 207\n",
      "chunk: 208\n",
      "chunk: 209\n",
      "chunk: 210\n",
      "chunk: 211\n",
      "chunk: 212\n",
      "chunk: 213\n",
      "chunk: 214\n",
      "chunk: 215\n",
      "chunk: 216\n",
      "chunk: 217\n",
      "chunk: 218\n",
      "chunk: 219\n",
      "chunk: 220\n",
      "chunk: 221\n",
      "chunk: 222\n",
      "chunk: 223\n",
      "chunk: 224\n",
      "chunk: 225\n",
      "chunk: 226\n",
      "chunk: 227\n",
      "chunk: 228\n",
      "chunk: 229\n",
      "chunk: 230\n",
      "chunk: 231\n",
      "chunk: 232\n",
      "chunk: 233\n",
      "chunk: 234\n",
      "chunk: 235\n",
      "chunk: 236\n",
      "chunk: 237\n",
      "chunk: 238\n",
      "chunk: 239\n",
      "chunk: 240\n",
      "chunk: 241\n",
      "chunk: 242\n",
      "chunk: 243\n",
      "chunk: 244\n",
      "chunk: 245\n",
      "chunk: 246\n",
      "chunk: 247\n",
      "chunk: 248\n",
      "chunk: 249\n",
      "chunk: 250\n",
      "chunk: 251\n",
      "chunk: 252\n",
      "chunk: 253\n",
      "chunk: 254\n",
      "chunk: 255\n",
      "chunk: 256\n",
      "chunk: 257\n",
      "chunk: 258\n",
      "chunk: 259\n",
      "chunk: 260\n",
      "chunk: 261\n",
      "chunk: 262\n",
      "chunk: 263\n",
      "chunk: 264\n",
      "chunk: 265\n",
      "chunk: 266\n",
      "chunk: 267\n",
      "chunk: 268\n",
      "chunk: 269\n",
      "chunk: 270\n",
      "chunk: 271\n",
      "chunk: 272\n",
      "chunk: 273\n",
      "chunk: 274\n",
      "chunk: 275\n",
      "chunk: 276\n",
      "chunk: 277\n",
      "chunk: 278\n",
      "chunk: 279\n",
      "chunk: 280\n",
      "chunk: 281\n",
      "chunk: 282\n",
      "chunk: 283\n",
      "chunk: 284\n",
      "chunk: 285\n",
      "chunk: 286\n",
      "chunk: 287\n",
      "chunk: 288\n",
      "chunk: 289\n",
      "chunk: 290\n",
      "chunk: 291\n",
      "chunk: 292\n",
      "chunk: 293\n",
      "chunk: 294\n",
      "chunk: 295\n",
      "chunk: 296\n",
      "chunk: 297\n",
      "chunk: 298\n",
      "chunk: 299\n",
      "chunk: 300\n",
      "chunk: 301\n",
      "chunk: 302\n",
      "chunk: 303\n",
      "chunk: 304\n",
      "chunk: 305\n",
      "chunk: 306\n",
      "chunk: 307\n",
      "chunk: 308\n",
      "chunk: 309\n",
      "chunk: 310\n",
      "chunk: 311\n",
      "chunk: 312\n",
      "chunk: 313\n",
      "chunk: 314\n",
      "chunk: 315\n",
      "chunk: 316\n",
      "chunk: 317\n",
      "chunk: 318\n",
      "chunk: 319\n",
      "chunk: 320\n",
      "chunk: 321\n",
      "chunk: 322\n",
      "chunk: 323\n",
      "chunk: 324\n",
      "chunk: 325\n",
      "chunk: 326\n",
      "chunk: 327\n",
      "chunk: 328\n",
      "chunk: 329\n",
      "chunk: 330\n",
      "chunk: 331\n",
      "chunk: 332\n",
      "chunk: 333\n",
      "chunk: 334\n",
      "chunk: 335\n",
      "chunk: 336\n",
      "chunk: 337\n",
      "chunk: 338\n",
      "chunk: 339\n",
      "chunk: 340\n",
      "chunk: 341\n",
      "chunk: 342\n",
      "chunk: 343\n",
      "chunk: 344\n",
      "chunk: 345\n",
      "chunk: 346\n",
      "chunk: 347\n",
      "chunk: 348\n",
      "chunk: 349\n",
      "chunk: 350\n",
      "chunk: 351\n",
      "chunk: 352\n",
      "chunk: 353\n",
      "chunk: 354\n",
      "chunk: 355\n",
      "chunk: 356\n",
      "chunk: 357\n",
      "chunk: 358\n",
      "chunk: 359\n",
      "chunk: 360\n",
      "chunk: 361\n",
      "chunk: 362\n",
      "chunk: 363\n",
      "chunk: 364\n",
      "chunk: 365\n",
      "chunk: 366\n",
      "chunk: 367\n",
      "chunk: 368\n",
      "chunk: 369\n",
      "chunk: 370\n",
      "chunk: 371\n",
      "chunk: 372\n",
      "chunk: 373\n",
      "chunk: 374\n",
      "chunk: 375\n",
      "chunk: 376\n",
      "chunk: 377\n",
      "chunk: 378\n",
      "chunk: 379\n",
      "chunk: 380\n",
      "chunk: 381\n",
      "chunk: 382\n",
      "chunk: 383\n",
      "chunk: 384\n",
      "chunk: 385\n",
      "chunk: 386\n",
      "chunk: 387\n",
      "chunk: 388\n",
      "chunk: 389\n",
      "chunk: 390\n",
      "chunk: 391\n",
      "chunk: 392\n",
      "chunk: 393\n",
      "chunk: 394\n",
      "chunk: 395\n",
      "chunk: 396\n",
      "chunk: 397\n",
      "chunk: 398\n",
      "chunk: 399\n",
      "chunk: 400\n",
      "chunk: 401\n",
      "chunk: 402\n",
      "chunk: 403\n",
      "chunk: 404\n",
      "chunk: 405\n",
      "chunk: 406\n",
      "chunk: 407\n",
      "chunk: 408\n",
      "chunk: 409\n",
      "chunk: 410\n",
      "chunk: 411\n",
      "chunk: 412\n",
      "chunk: 413\n",
      "chunk: 414\n",
      "chunk: 415\n",
      "chunk: 416\n",
      "chunk: 417\n",
      "chunk: 418\n",
      "chunk: 419\n",
      "chunk: 420\n",
      "chunk: 421\n",
      "chunk: 422\n",
      "chunk: 423\n",
      "chunk: 424\n",
      "chunk: 425\n",
      "chunk: 426\n",
      "chunk: 427\n",
      "chunk: 428\n",
      "chunk: 429\n",
      "chunk: 430\n",
      "chunk: 431\n",
      "chunk: 432\n",
      "chunk: 433\n",
      "chunk: 434\n",
      "chunk: 435\n",
      "chunk: 436\n",
      "chunk: 437\n",
      "chunk: 438\n",
      "chunk: 439\n",
      "chunk: 440\n",
      "chunk: 441\n",
      "chunk: 442\n",
      "chunk: 443\n",
      "chunk: 444\n",
      "chunk: 445\n",
      "chunk: 446\n",
      "chunk: 447\n",
      "chunk: 448\n",
      "chunk: 449\n",
      "chunk: 450\n",
      "chunk: 451\n",
      "chunk: 452\n",
      "chunk: 453\n",
      "chunk: 454\n",
      "chunk: 455\n",
      "chunk: 456\n",
      "chunk: 457\n",
      "chunk: 458\n",
      "chunk: 459\n",
      "chunk: 460\n",
      "chunk: 461\n",
      "chunk: 462\n",
      "chunk: 463\n",
      "chunk: 464\n",
      "chunk: 465\n",
      "chunk: 466\n",
      "chunk: 467\n",
      "chunk: 468\n",
      "chunk: 469\n",
      "chunk: 470\n",
      "chunk: 471\n",
      "chunk: 472\n",
      "chunk: 473\n",
      "chunk: 474\n",
      "chunk: 475\n",
      "chunk: 476\n",
      "chunk: 477\n",
      "chunk: 478\n",
      "chunk: 479\n",
      "chunk: 480\n",
      "chunk: 481\n",
      "chunk: 482\n",
      "chunk: 483\n",
      "chunk: 484\n",
      "chunk: 485\n",
      "chunk: 486\n",
      "chunk: 487\n",
      "chunk: 488\n",
      "chunk: 489\n",
      "chunk: 490\n",
      "chunk: 491\n",
      "chunk: 492\n",
      "chunk: 493\n",
      "chunk: 494\n",
      "chunk: 495\n",
      "chunk: 496\n"
     ]
    }
   ],
   "source": [
    "token_list = []\n",
    "for i,chunk in enumerate(chunks):\n",
    "    print(\"chunk:\",i)\n",
    "    token_list += tokenizer.encode(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087269997"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Corteza de ''E. fibrosa''. '''Corteza de hierro''' (Ironbark) es el nombre que se le da varias especies en tres grupos taxonómicos dentro del género de ''Eucalyptus'' que tienen la corteza oscura profundamente surcada. En vez de mudarla anualmente como en muchas otras especies de ''Eucalyptus'', la corteza muerta se acumula en los árboles, formando las fisuras. Se hace rugosa después de resecarse impregnarse con k\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('token_list.data', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(token_list, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('token_list.data', 'rb') as filehandle:\n",
    "#    token_list = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 100 ms, total: 29.4 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "examples = []\n",
    "block_size = 1000\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "for i in range(0, len(token_list) - block_size + 1, block_size):\n",
    "    examples.append(token_list[i:i + block_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examples = [token_list[i:i + block_size] for i in range(0, len(token_list), block_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1087269, 1000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples), len(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = [], []\n",
    "\n",
    "for ex in examples:\n",
    "    inputs.append(ex[:-1])\n",
    "    labels.append(ex[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPUs =tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPUs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "#dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(dataset, './tensorflow_dataset', compression=None, shard_func=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    time.sleep(1)\n",
    "    print('hola')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "\n",
    "# definining our loss function\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# defining our metric which we want to observe\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tf2_transformers",
   "language": "python",
   "name": "conda_tf2_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
